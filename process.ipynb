{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理数据，生成一个大的npy文件\n",
    "导入os、numpy、PIL库，并确保tqdm库可用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件夹路径\n",
    "image_dir = 'data/Img'\n",
    "mask_dir = 'data/Lab'\n",
    "\n",
    "# 获取文件列表\n",
    "images = sorted(os.listdir(image_dir))\n",
    "masks = sorted(os.listdir(mask_dir))\n",
    "\n",
    "# 确保文件对应\n",
    "assert len(images) == len(masks), \"图片和掩码数量不一致\"\n",
    "\n",
    "# 完整路径\n",
    "image_paths = [os.path.join(image_dir, img) for img in images]\n",
    "mask_paths = [os.path.join(mask_dir, msk) for msk in masks]\n",
    "\n",
    "# 分割数据集\n",
    "train_imgs, test_imgs, train_masks, test_masks = train_test_split(\n",
    "    image_paths, mask_paths, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "def load_images(paths):\n",
    "    data = []\n",
    "    for path in paths:\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        data.append(np.array(img))\n",
    "    return np.array(data)\n",
    "\n",
    "def load_masks(paths):\n",
    "    data = []\n",
    "    for path in paths:\n",
    "        img = Image.open(path).convert('L')\n",
    "        data.append(np.array(img))\n",
    "    return np.array(data)\n",
    "\n",
    "# 加载并保存训练集\n",
    "train_images = load_images(train_imgs)\n",
    "train_masks = load_masks(train_masks)\n",
    "np.save('data/train_images.npy', train_images)\n",
    "np.save('data/train_masks.npy', train_masks)\n",
    "\n",
    "# 加载并保存测试集\n",
    "test_images = load_images(test_imgs)\n",
    "test_masks = load_masks(test_masks)\n",
    "np.save('data/test_images.npy', test_images)\n",
    "np.save('data/test_masks.npy', test_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{'work_dir': './work_dir/', 'config': './config/train.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'feeder': 'feeder.Feeder', 'num_worker': 8, 'train_feeder_args': {'mode': 'train', 'data_path': './data/train_images.npy', 'label_path': './data/train_masks.npy'}, 'test_feeder_args': {'mode': 'test', 'data_path': './data/test_images.npy', 'label_path': './data/test_masks.npy'}, 'model': 'net.self_net', 'model_args': {'num_class': 4, 'channel': 3}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.01, 'step': [10, 50], 'device': 0, 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 16, 'test_batch_size': 16, 'start_epoch': 0, 'num_epoch': 150, 'weight_decay': 0.0001}\n",
      "\n",
      "Epoch:[1/150]\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]torch.Size([16, 200, 200, 3]) torch.Size([16, 200, 200])\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pdch/workspace/Segmodel/main.py\", line 215, in <module>\n",
      "    processor.start()\n",
      "  File \"/home/pdch/workspace/Segmodel/main.py\", line 191, in start\n",
      "    self.train()\n",
      "  File \"/home/pdch/workspace/Segmodel/main.py\", line 113, in train\n",
      "    output = self.model.forward(data)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/pdch/workspace/Segmodel/net/model.py\", line 488, in forward\n",
      "    x_spconv = self.SPConv(x) #128 25 25\n",
      "               ^^^^^^^^^^^^^^\n",
      "  File \"/home/pdch/miniforge3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/pdch/miniforge3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/pdch/miniforge3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/home/pdch/miniforge3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/pdch/miniforge3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/pdch/miniforge3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/conv.py\", line 554, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/pdch/miniforge3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n",
      "    return F.conv2d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: Given groups=1, weight of size [32, 3, 3, 3], expected input[16, 200, 200, 3] to have 3 channels, but got 200 channels instead\n",
      "Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x7f0450a71260>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pdch/miniforge3/envs/torch/lib/python3.12/site-packages/tensorboardX/writer.py\", line 108, in cleanup\n",
      "    self.event_writer.close()\n",
      "  File \"/home/pdch/miniforge3/envs/torch/lib/python3.12/site-packages/tensorboardX/event_file_writer.py\", line 157, in close\n",
      "    self._worker.stop()\n",
      "  File \"/home/pdch/miniforge3/envs/torch/lib/python3.12/site-packages/tensorboardX/event_file_writer.py\", line 188, in stop\n",
      "    self._queue.put(self._shutdown_signal)\n",
      "  File \"/home/pdch/miniforge3/envs/torch/lib/python3.12/multiprocessing/queues.py\", line 94, in put\n",
      "    self._start_thread()\n",
      "  File \"/home/pdch/miniforge3/envs/torch/lib/python3.12/multiprocessing/queues.py\", line 177, in _start_thread\n",
      "    self._thread.start()\n",
      "  File \"/home/pdch/miniforge3/envs/torch/lib/python3.12/threading.py\", line 971, in start\n",
      "    _start_new_thread(self._bootstrap, ())\n",
      "RuntimeError: can't create new thread at interpreter shutdown\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
